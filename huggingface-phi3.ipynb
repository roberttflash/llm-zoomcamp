{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "506fab2a-a50c-42bd-a106-c83a9d2828ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\r\n"
     ]
    }
   ],
   "source": [
    "!rm -f minsearch.py\n",
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ba026a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  3832  100  3832    0     0  20487      0 --:--:-- --:--:-- --:--:-- 20491\n"
     ]
    }
   ],
   "source": [
    "!curl -o minsearch.py https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ac947de-effd-4b61-8792-a6d7a133f347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7fa6a9e33a00>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "import minsearch\n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f087272-b44d-4738-9ea2-175ec63a058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "742ab881-499a-4675-83c4-2013ea1377b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='phi3',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe8bff3e-b672-42be-866b-f2d9bb217106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "988ece59-951a-4b32-ba3f-cb8efb66a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caf7561f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This statement appears to be part of an instruction set, possibly for testing purposes or as a placeholder text within templates where actual tests are developed later on by human operators based upon specific criteria and objectives outlined in more detailed documents such as READMEs, configuration files, or system requirements documentation. To convert this into executable instructions following standard practices:\\n\\n1. Create an automated script/program to replace placeholder text with real test content when ready for testing. This can be achieved using string replacement functions available within the programming language being used (e.g., `string_replace` in Python). The initial input, \"This is a test.\", would initially remain as-is or replaced by this template if that\\'s part of an automated system setup process until it receives instructions to replace with actual testing content:\\n    ```python\\n        # Example using Python for text replacement within templates\\n        placeholder_text = \\'This is a TEST.\\'  # Placeholder string in the test document/template.\\n        final_test_content = input().replace(\\'TEST\\', \\'\\')  # Replace placeholders with actual content when ready to run tests.\\n    ```\\n2. If this sentence needs to be included as part of testing output for some reason, such code could include conditional checks or logging that outputs the original placeholder text while noting it\\'s temporary:\\n    ```python\\n        if is_placeholder(\\'This is a test.\\'):  # Hypothetical function checking whether content is a template placeholder.\\n            print(\"NOTE: \\'This is a TEST\\' will be replaced with actual tests upon setup completion.\")\\n        else:\\n            print(finalized_test_content)   # Actual test content to execute and run as part of the testing suite when ready (not shown).\\n    ```\\n3. In any automated system or documentation where this sentence is used, guidelines must be provided for how it should evolve into meaningful tests that are relevant to the specific scenario being tested:\\n    - The test content will vary depending on what exactly needs testing in terms of functionality (e.g., login process).\\n    - Test cases would include valid and invalid inputs while verifying system responses, ensuring robustness against errors or unexpected behavior during actual usage scenarios.\\n    ```markdown\\n        # Example Documentation Markup for Guidelines on Replacing Placeholder Text with Actual Content: \\n        \\n        ## Temporary Test Suite Placement (This is a TEST.):\\n        ### Current State of Use Case Template:\\n            - Replace placeholder text \"This is a test.\" with actual scenarios, inputs and expected outputs for testing. Fill the following details in respective sections to develop comprehensive tests which verify that software behaves as intended across different conditions/edge cases (detailed instructions here). This template will serve only until we create more concrete content based on defined objectives like [testing login functionality](URL_to_login_functionalities_test), ensuring proper session management and security protocols, etc.\\n        ### Replacement Procedure: \\n            - Review the system requirements document to understand specific testing needs. Use provided scenarios as test cases replacing placeholder text where applicable using string replacement methods available in your development environment/tools (referenced README or similar files for exact syntax). Ensure all tests are executable, well-documented with expected outcomes clearly marked and stored securely until the end of this phase to avoid execution on subsequent unrelated test cycles.\\n    ```'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm('write that this is a test.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23a5b162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This statement appears to be part of an instruction set, possibly for testing purposes or as a placeholder text within templates where actual tests are developed later on by human operators based upon specific criteria and objectives outlined in more detailed documents such as READMEs, configuration files, or system requirements documentation. To convert this into executable instructions following standard practices:\n",
      "\n",
      "1. Create an automated script/program to replace placeholder text with real test content when ready for testing. This can be achieved using string replacement functions available within the programming language being used (e.g., `string_replace` in Python). The initial input, \"This is a test.\", would initially remain as-is or replaced by this template if that's part of an automated system setup process until it receives instructions to replace with actual testing content:\n",
      "    ```python\n",
      "        # Example using Python for text replacement within templates\n",
      "        placeholder_text = 'This is a TEST.'  # Placeholder string in the test document/template.\n",
      "        final_test_content = input().replace('TEST', '')  # Replace placeholders with actual content when ready to run tests.\n",
      "    ```\n",
      "2. If this sentence needs to be included as part of testing output for some reason, such code could include conditional checks or logging that outputs the original placeholder text while noting it's temporary:\n",
      "    ```python\n",
      "        if is_placeholder('This is a test.'):  # Hypothetical function checking whether content is a template placeholder.\n",
      "            print(\"NOTE: 'This is a TEST' will be replaced with actual tests upon setup completion.\")\n",
      "        else:\n",
      "            print(finalized_test_content)   # Actual test content to execute and run as part of the testing suite when ready (not shown).\n",
      "    ```\n",
      "3. In any automated system or documentation where this sentence is used, guidelines must be provided for how it should evolve into meaningful tests that are relevant to the specific scenario being tested:\n",
      "    - The test content will vary depending on what exactly needs testing in terms of functionality (e.g., login process).\n",
      "    - Test cases would include valid and invalid inputs while verifying system responses, ensuring robustness against errors or unexpected behavior during actual usage scenarios.\n",
      "    ```markdown\n",
      "        # Example Documentation Markup for Guidelines on Replacing Placeholder Text with Actual Content: \n",
      "        \n",
      "        ## Temporary Test Suite Placement (This is a TEST.):\n",
      "        ### Current State of Use Case Template:\n",
      "            - Replace placeholder text \"This is a test.\" with actual scenarios, inputs and expected outputs for testing. Fill the following details in respective sections to develop comprehensive tests which verify that software behaves as intended across different conditions/edge cases (detailed instructions here). This template will serve only until we create more concrete content based on defined objectives like [testing login functionality](URL_to_login_functionalities_test), ensuring proper session management and security protocols, etc.\n",
      "        ### Replacement Procedure: \n",
      "            - Review the system requirements document to understand specific testing needs. Use provided scenarios as test cases replacing placeholder text where applicable using string replacement methods available in your development environment/tools (referenced README or similar files for exact syntax). Ensure all tests are executable, well-documented with expected outcomes clearly marked and stored securely until the end of this phase to avoid execution on subsequent unrelated test cycles.\n",
      "    ```\n"
     ]
    }
   ],
   "source": [
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8260f54e",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
